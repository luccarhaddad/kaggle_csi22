{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Titanic Project - Survival Prediction"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["CSI-22 (Object-Oriented Programming)\n","\n","Group members: André Diogo, Antônio Gustavo and Lucca Haddad"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Importing Libraries"]},{"cell_type":"code","execution_count":537,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Defining Parameters"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Here, we define different parameters for both logistic regression and random forest models. Thus, we can analyse their dynamics with distinct hyperparameters."]},{"cell_type":"code","execution_count":538,"metadata":{},"outputs":[],"source":["log_reg_params = [{\"C\":0.01}, {\"C\":0.1}, {\"C\":1}, {\"C\":10}]\n","rand_for_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n","naive_bayes_params = [{}]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### List of Models"]},{"cell_type":"code","execution_count":539,"metadata":{},"outputs":[],"source":["modelclasses = [\n","    [\"log regression\", LogisticRegression, log_reg_params],\n","    [\"random forest\", RandomForestClassifier, rand_for_params],\n","    [\"naive bayes\", GaussianNB, naive_bayes_params],\n","]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Importing Problem's Data"]},{"cell_type":"code","execution_count":540,"metadata":{},"outputs":[],"source":["train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Variable Replacement, Invalid Variable Removal"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In this section, we replace both 'Sex' and 'Embarked' strings/chars features with numbers, remove the NAN from the 'Embarked' column and drop the columns we don't see as coherent for analysis (Name, Cabin and Ticket)."]},{"cell_type":"code","execution_count":541,"metadata":{},"outputs":[],"source":["train = train.replace('male', 0)\\\n","    .replace('female', 1)\\\n","    .replace('S', 0)\\\n","    .replace('C', 1)\\\n","    .replace('Q', 2)\\\n","    .dropna(subset=['Embarked'])\\\n","    .drop(['Name','Cabin','Ticket'], axis=1)\n","\n","train['Age'].fillna(train['Age'].mean(),inplace=True)\n","\n","test = test.replace('male', 0)\\\n","    .replace('female', 1)\\\n","    .replace('S', 0)\\\n","    .replace('C', 1)\\\n","    .replace('Q', 2)\\\n","    .drop(['Name','Cabin','Ticket'], axis=1)\n","\n","test['Age'].fillna(test['Age'].mean(),inplace=True)\n","test['Fare'].fillna(test['Fare'].mean(),inplace=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In the test dataframe, we need as specific number of rows after prediction, so we didn't remove the rows with NAN; instead, the missing values we're replaced with the average value of the respective column."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Min-Max Normalization (Age and Fare)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["To reduce the range between minimum and maximum values of both Fare and Age features, we replaced its values with a min-max normalization."]},{"cell_type":"code","execution_count":542,"metadata":{},"outputs":[],"source":["train.Fare = (train.Fare - train.Fare.min())/(train.Fare.max() - train.Fare.min())\n","train.Age = (train.Age - train.Age.min())/(train.Age.max() - train.Age.min())\n","\n","test.Fare = (test.Fare - test.Fare.min())/(test.Fare.max() - test.Fare.min())\n","test.Age = (test.Age - test.Age.min())/(test.Age.max() - test.Age.min())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Feature Selection"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Perform a random split for train and test and select the feature and the target columns."]},{"cell_type":"code","execution_count":543,"metadata":{},"outputs":[],"source":["feature_cols = ['PassengerId','Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n","x = train[feature_cols]\n","y = train.Survived\n","\n","x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=123)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Iterate over the different models and respective hyperparameters selected."]},{"cell_type":"code","execution_count":544,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/haddad/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/haddad/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/haddad/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/home/haddad/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["insights = []\n","for modelname, Model, params_list in modelclasses:\n","    for params in params_list:\n","        model = Model(**params)\n","        model.fit(x_train, y_train)\n","        score = model.score(x_test, y_test)\n","        insights.append((modelname, model, params, score))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Print the performance of the various models after prediction."]},{"cell_type":"code","execution_count":545,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["random forest {'criterion': 'gini'} 0.8258426966292135\n","random forest {'criterion': 'entropy'} 0.8202247191011236\n","log regression {'C': 0.1} 0.7752808988764045\n","naive bayes {} 0.7752808988764045\n","log regression {'C': 10} 0.7696629213483146\n","log regression {'C': 1} 0.7640449438202247\n","log regression {'C': 0.01} 0.702247191011236\n"]}],"source":["insights.sort(key=lambda x:x[-1], reverse=True)\n","for modelname, model, params, score in insights:\n","    print(modelname, params, score)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Here, we remake the prediction with the model that had the best performance, now using the desired database."]},{"cell_type":"code","execution_count":546,"metadata":{},"outputs":[],"source":["final_model = RandomForestClassifier(criterion='gini')\n","final_model.fit(x_train, y_train)\n","test['Survived'] = final_model.predict(test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Generates a CSV of the final database after prediction."]},{"cell_type":"code","execution_count":547,"metadata":{},"outputs":[],"source":["final = test[['PassengerId','Survived']]\n","final.to_csv('final.csv',index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
